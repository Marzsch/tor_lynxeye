
# 0/ Executive Summary (ToR Purpose)

Wildfire risk governance increasingly depends on the ability of public authorities to make **timely, proportionate, and well-targeted decisions** under conditions of high environmental uncertainty and binding operational constraints. Despite advances in risk modeling, public action remains limited by **information gaps, latency, and incomplete territorial coverage**.

The **LynxSense framework** is conceived as a **public decision-support system** designed to strengthen the **informational environment** in which wildfire-related decisions are made. Rather than acting directly on the physical environment, LynxSense provides decision-makers with a **Dynamic Risk Map**, continuously updated and accompanied by metadata describing the **quality, coverage, and timeliness** of the information delivered.

The purpose of this Terms of Reference is to define the framework under which LynxSense is deployed and evaluated, focusing on whether improvements in information quality enhance the **alignment between observed wildfire risk and public decisions**. The proposed evaluation assesses LynxSense as an **informational amplifier**, improving decision responsiveness and proportionality under uncertainty, rather than increasing decision intensity per se.

# I/ Context and Strategic Background

Over the past decade, **wildfire risk has undergone a profound transformation across Europe**, driven by the combined effects of **climate change, prolonged droughts, recurring heatwaves, and increasing ecosystem stress**. These structural shifts have altered fire behavior in depth, resulting in **longer fire seasons**, **higher ignition probabilities**, and **faster, less predictable propagation dynamics**, particularly across the **Mediterranean basin**.

Southern Europe—and Southern France in particular—has become a region of **systemic exposure**, where wildfire risk can no longer be understood as a series of isolated seasonal events. The 2022 wildfire season in France, during which more than **60,000 hectares burned**, illustrated how rapidly extreme climatic conditions can overwhelm existing prevention and response mechanisms, even in territories historically considered moderately exposed. This episode marked a turning point, revealing that wildfire risk has evolved into a **structural constraint on territorial governance**.

This transformation is not solely climatic in nature. It is amplified by **land-use patterns**, **vegetation continuity**, and **growing human pressure** at the wildland–urban interface. As a result, wildfire risk increasingly emerges from the interaction between environmental stressors and human activity, producing **highly localized, heterogeneous, and rapidly evolving risk conditions** that challenge traditional monitoring paradigms.

In parallel, wildfire governance has benefited from significant institutional and technological advances. At both national and European levels, major frameworks have been deployed to strengthen monitoring, prevention, and civil protection capacities. In France, these include the **Plan National d’Adaptation au Changement Climatique (PNACC 2)** and the **National Strategy for Forest and Vegetation Fire Risk Management (2023–2030)**. At the European level, mechanisms such as the **EU Civil Protection Mechanism (UCPM)**, **RescEU**, the **European Forest Fire Information System (EFFIS)**, and the **Copernicus Emergency Management Service (EMS)** have substantially improved satellite observation, meteorological modelling, and cross-border coordination.

Despite this dense institutional architecture and the growing availability of macro-scale environmental data, public authorities continue to face **persistent blind spots** in their ability to anticipate and manage wildfire risk. Existing systems remain primarily oriented toward **periodic, large-scale observation**, offering limited capacity to capture **fine-scale environmental variations**, **intra-day risk dynamics**, and **localized ignition conditions** that are critical for early decision-making.

This gap is particularly problematic in territories characterized by strong spatial heterogeneity, where ignition probability and propagation potential can vary sharply over short distances and time intervals. Public authorities are therefore required to make decisions under conditions of **high uncertainty**, while relying on information systems that were not designed to support **continuous, localized, and decision-relevant risk assessment**.

The result is a growing mismatch between the **temporal and spatial dynamics of wildfire risk** and the **informational context in which public decisions are taken**. This mismatch constrains the ability of institutions to move beyond reactive response and toward **proactive, anticipatory wildfire governance**, even when political will, operational capacity, and institutional coordination are present.

It is within this context that the **LynxSense framework** has been conceived. Rather than replacing existing national and European infrastructures, LynxSense is designed as a **complementary, AI-enabled information system**, capable of delivering **continuous, multi-source, high-resolution environmental intelligence** at the local level. By strengthening the informational foundations of public action, the framework aims to support more timely, better targeted, and more proportionate wildfire risk management across high-exposure Mediterranean territories.


# II/ Problem Statement: Wildfire Risk Governance and Decision-Making Challenges

### 1) Wildfire Risk as a Decision Problem Under Uncertainty

Within the strategic context described above, wildfire risk governance emerges primarily as a **decision-making problem under uncertainty**. Public authorities are not only confronted with a higher frequency of extreme events, but with the need to make **time-sensitive decisions**—related to prevention, preparedness, and resource allocation—under rapidly changing and partially observed conditions.

At this stage, the challenge is no longer to recognize the existence of wildfire risk, but to determine **how public action should be adjusted in real time** as risk levels evolve. Decisions must be taken under binding operational and budgetary constraints, often before risk fully materializes, and with limited margins for correction once interventions are deployed. In this setting, the effectiveness of public action depends critically on its **timing, spatial targeting, and proportionality** relative to underlying risk dynamics.

Wildfire governance is therefore less a question of intervention capacity than of **decision quality conditioned by information availability**. When risk signals are delayed, aggregated, or weakly connected to operational choices, even well-coordinated institutions face systematic difficulties in aligning action with evolving risk conditions.

### 2) Decision Constraints and Information Asymmetries

In practice, public decision-making is shaped by a set of **structural constraints** that interact directly with the informational environment. Preventive and preparatory measures—such as patrol deployment, surveillance missions, or resource pre-positioning—must often be planned in advance, based on forecasts or indicators that may lose relevance within hours.

At the same time, wildfire risk evolves at a much higher temporal frequency. Short-term changes in weather conditions, vegetation stress, or human activity can generate abrupt shifts in ignition probability and propagation potential. This creates a persistent **asymmetry between the speed of risk dynamics and the pace at which decisions can be revised**, particularly when information updates are infrequent or spatially coarse.

These constraints are further amplified by the need to coordinate decisions across multiple administrative levels and operational actors. As a result, public authorities operate in a decision environment where **information is structurally incomplete at the moment when it is most needed**, limiting the capacity to adjust actions dynamically as conditions evolve.


### 3) Limits of Existing Decision-Support Systems

Although existing monitoring and prevention systems provide valuable situational awareness, they remain **weakly aligned with the needs of operational decision-making**. Most systems have been designed to support regional-scale monitoring, post-event assessment, or strategic planning, rather than continuous, fine-grained decision support.

Information is typically delivered through aggregated indicators, periodic updates, and separate data streams. Local environmental signals, short-term anomalies, and micro-scale risk variations are rarely integrated into a unified operational picture that can be directly mobilized for decision-making. As a consequence, available information often lacks **decision salience** at the spatial and temporal scales at which preventive action must be taken.

This structural limitation does not prevent action, but it **distorts it**: decisions are taken with partial visibility, forcing authorities to rely on precautionary heuristics or reactive adjustments rather than on continuous risk-informed guidance.

### 4) Implications for Wildfire Risk Governance

The interaction between rapid risk dynamics, constrained decision processes, and limited decision-relevant information produces a governance model that remains **predominantly reactive**, even in the presence of strong institutional frameworks and growing technical capacity.

Preventive actions may be initiated too late, insufficiently targeted, or weakly correlated with localized risk conditions. Conversely, resources may be over-mobilized to compensate for uncertainty, generating inefficiencies and opportunity costs elsewhere in the system. These outcomes reflect not a lack of commitment or coordination, but a **structural misalignment between how wildfire risk evolves and how decisions are informed**.

Improving wildfire risk governance therefore requires more than incremental improvements in monitoring or response capacity. It calls for an intervention that directly addresses the **informational foundations of public decision-making**, by reducing uncertainty at the moment decisions are taken and by improving the alignment between observed risk and public action.

It is this specific governance challenge—emerging from the context described in Section I—that motivates the intervention presented in the following section.


# III. Overview of the Proposed Solution: The LynxSense Framework

### 1. Project vision and value proposition  

The LynxSense framework is conceived as a **decision-support system** designed to address the governance challenges identified in the previous section. Its primary objective is not to intervene directly on wildfire events, but to **improve the informational environment** in which public authorities assess risk and make preventive and preparatory decisions.

LynxSense is built on the premise that wildfire risk governance can be significantly strengthened by providing **continuous, localized, and decision-relevant environmental intelligence**. By reducing informational uncertainty at the moment decisions are taken, the framework aims to improve the **timeliness, targeting, and proportionality** of public action under constrained operational and budgetary conditions.

The value proposition of LynxSense therefore lies in its capacity to transform heterogeneous environmental observations into **actionable risk signals**, enabling public authorities to move from predominantly reactive approaches toward more anticipatory and risk-informed governance practices.

### 2. System overview and functional architecture  

LynxSense is designed as an **integrated, modular system** combining data acquisition, analytical processing, and decision-support functionalities within a unified framework. The system operates continuously, ingesting information from multiple sources and updating risk assessments as new data become available.

At a high level, the framework is structured around three functional layers :

- a **data acquisition layer**, responsible for collecting heterogeneous environmental observations;  
- an **analytical and inference layer**, where data are processed, integrated, and translated into risk assessments;
- a **decision-support layer**, providing public authorities with dynamic risk representations and operational insights.

This layered architecture ensures scalability, adaptability, and interoperability with existing national and European monitoring and civil protection infrastructures, while maintaining a clear focus on decision relevance.

### 3. Multi-source data acquisition strategy  

The LynxSense framework relies on a **multi-source data acquisition strategy** to capture the complexity and heterogeneity of wildfire risk dynamics. Data inputs include ground-based environmental sensors, autonomous aerial platforms, satellite imagery, and meteorological forecasts.

Each data source contributes complementary information at different spatial and temporal resolutions. Ground sensors provide localized, high-frequency measurements of environmental conditions; aerial platforms enable targeted observation of high-risk zones; satellite imagery offers broad territorial coverage; and meteorological data support short-term risk anticipation.

By combining these heterogeneous sources, LynxSense aims to overcome the limitations of single-source monitoring systems and to ensure **robust coverage of localized and rapidly evolving risk conditions**.

### 4. Integrated intelligence layer and decision support  

At the core of the LynxSense framework lies an **integrated intelligence layer** responsible for transforming raw environmental data into decision-relevant risk information. This layer continuously fuses incoming observations, updates risk assessments, and generates dynamic representations of wildfire risk across the monitored territory.

The primary output of this process is a **Dynamic Risk Map**, which provides public authorities with a continuously updated view of ignition and propagation risk at a fine spatial scale. This representation is designed to support operational decision-making by highlighting priority areas, emerging risk patterns, and short-term risk escalation.

By delivering **timely, localized, and interpretable risk information**, the decision-support layer enables public authorities to better align preventive and preparatory actions with observed risk dynamics, addressing the governance challenges outlined in Section II.

# IV. Methodological Framework

The LynxSense framework is built upon a **continuous, adaptive, and multi-layer methodological architecture** designed to monitor wildfire risk in real time.

Rather than relying on static danger maps or periodic assessments, LynxSense operates as a **dynamic information framework**, in which risk indicators are continuously updated as new environmental observations become available. The system functions as a living analytical structure, capable of integrating heterogeneous data streams and recalibrating its internal state in response to evolving conditions.

From a methodological perspective, LynxSense is conceived as an **information-generation and structuring system**. Its primary objective is to **reduce uncertainty** faced by public authorities when monitoring wildfire-prone territories. The framework does not aim to directly prevent or suppress fires, nor to prescribe operational actions. Instead, it is designed to **produce timely, spatially coherent, and interpretable risk signals**, enabling authorities to make more informed, proportionate, and context-aware decisions.

By design, LynxSense remains **decision-neutral**. It modifies the informational environment in which decisions are taken, without automating or constraining the decision-making process itself. This separation between information production and operational authority is a core methodological principle, ensuring institutional compatibility, accountability, and evaluability.

The methodological architecture of LynxSense relies on three complementary components:

- **Dynamic Risk Clusters (DRCs)** — a targeted, data-driven observation strategy focusing on zones with high ignition potential and propagation sensitivity.
- **A real-time analytical pipeline** — responsible for ingesting, harmonizing, and continuously updating heterogeneous environmental data streams.
- **Propagation and spatial inference models** — designed to capture interdependencies between monitored zones and extrapolate risk beyond directly observed locations.

Together, these components enable the production of **high-resolution, continuously updated wildfire intelligence**, linking localized environmental stress signals to broader spatial dynamics. The following sections describe each component in detail, before presenting a transversal, end-to-end view of the methodology.

### 1. Dynamic Risk Clusters (DRCs): a targeted observation strategy

At the core of the LynxSense methodology lies the concept of **Dynamic Risk Clusters (DRCs)**.  
DRCs are localized environmental units designed to represent areas where wildfire ignition and early propagation are structurally more likely to occur.

Rather than attempting exhaustive territorial monitoring, LynxSense adopts a **targeted observation strategy**, concentrating sensing and analytical efforts on a limited number of high-value zones. This methodological choice reflects a deliberate trade-off between spatial coverage and informational depth, under which monitoring fewer, well-selected areas yields more actionable insights than sparse, uniform coverage across large territories.

#### Identification and characterization of high-risk zones

Dynamic Risk Clusters are identified through a multi-criteria assessment combining long-term structural and contextual factors, including:

- vegetation type, biomass density, and fuel continuity,
- topography, slope orientation, and terrain complexity,
- historical fire occurrence and recurrence patterns,
- patterns of human activity and accessibility,
- and long-term meteorological and climatic exposure.

This assessment isolates zones that are **intrinsically vulnerable**, either because they exhibit a higher probability of ignition or because they act as accelerators of fire spread under adverse environmental conditions.

The identification phase relies primarily on pre-deployment data and expert knowledge. It precedes any real-time monitoring activity and serves to anchor the framework in a robust understanding of the territory’s structural vulnerability.

#### DRCs as adaptive environmental units

Once selected, each Dynamic Risk Cluster functions as an **adaptive environmental unit**.  
It aggregates localized observations describing vegetation stress, dryness, and microclimatic conditions, which are continuously updated as new data become available through the monitoring infrastructure.

Beyond their role as observation points, DRCs also serve as **representative sampling nodes** within the broader territory. Fine-scale information collected within a cluster can be partially extrapolated to surrounding areas through spatial inference mechanisms, allowing the framework to extend its informational reach beyond directly instrumented locations.

This dual role—local observation and regional representation—enables LynxSense to bridge the gap between micro-scale environmental dynamics and landscape-level risk understanding.

#### Methodological advantages of the DRC approach

The Dynamic Risk Cluster methodology provides several structural advantages:

- **Improved precision**, through localized, high-resolution monitoring of ignition-relevant variables.
- **Reduced latency**, by enabling rapid detection of environmental changes in critical zones.
- **Enhanced scalability**, by limiting the need for exhaustive instrumentation across the entire territory.

In this sense, DRCs constitute the **structural backbone** of the LynxSense framework. They anchor both data acquisition and spatial reasoning, ensuring that the system’s analytical resources are concentrated where they generate the highest informational value.

### 2. Analytical pipeline: from heterogeneous data to dynamic risk signals

The analytical pipeline constitutes the **central information-processing layer** of the LynxSense framework.  
Its methodological role is to transform heterogeneous environmental observations into coherent, temporally consistent, and continuously updated risk indicators.

Rather than operating through batch processing or fixed update cycles, the pipeline is designed as a **continuous analytical flow**, in which data ingestion, fusion, and risk estimation evolve in real time as new observations become available.

#### Multi-source data ingestion and preprocessing

The pipeline ingests environmental data from multiple sources, including in situ sensors, satellite observations, meteorological services, and, where relevant, autonomous drone systems. These inputs differ significantly in terms of spatial resolution, temporal frequency, and data structure.

To ensure analytical coherence, incoming data streams undergo a series of preprocessing steps, including spatio-temporal alignment, normalization, and validation. These operations transform raw observations into harmonized variables that can be jointly analyzed within a unified framework.

This ingestion layer is designed to be resilient to missing data, asynchronous updates, and measurement noise, reflecting the operational constraints of environmental monitoring systems.

#### Real-time data fusion and continuous updating

At the core of the pipeline lies a **real-time data fusion mechanism**, which integrates heterogeneous observations into stable estimates of local environmental conditions. Filtering and interpolation techniques are used to maintain continuity of estimates despite incomplete or noisy inputs, while preserving sensitivity to newly observed changes.

This approach allows LynxSense to reconcile high-frequency local measurements with lower-frequency regional observations, ensuring consistency across spatial and temporal scales.

Importantly, data fusion is performed continuously rather than retrospectively. Risk indicators are therefore recalculated each time new information enters the system, without reliance on predefined update schedules or static thresholds.

#### Continuous risk recalibration

As environmental conditions evolve, the analytical pipeline automatically recalibrates local indicators describing vegetation stress, dryness, and microclimatic states. These updates propagate through the framework, affecting both cluster-level risk estimates and inferred conditions in neighboring zones.

This recalibration mechanism ensures that wildfire risk assessment remains synchronized with the current state of the environment, capturing rapid intra-day variations as well as slower structural shifts.

Throughout this process, the analytical pipeline remains **decision-neutral**.  
It produces structured, interpretable information but does not prescribe operational actions. The transformation of risk signals into preventive or preparedness decisions remains entirely under the responsibility of public authorities.

### 3. Propagation and spatial inference models: from local signals to landscape dynamics

Wildfire risk is inherently **spatially interdependent**.  
Environmental conditions observed in one location can rapidly influence neighboring areas through wind, topography, fuel continuity, and dryness gradients. Capturing these interactions is therefore essential to understanding wildfire dynamics beyond isolated observation points.

To model this spatial complexity, LynxSense represents the monitored territory as a **network of interconnected Dynamic Risk Clusters**. In this representation, each node corresponds to a DRC, while edges encode potential pathways through which risk may propagate across the landscape.

#### Modeling spatial dependencies and propagation pathways

Propagation pathways are characterized by weighted relationships between clusters, reflecting the relative ease with which fire-related risk can diffuse from one zone to another. These weights are derived from structural and dynamic factors, including:

- wind alignment and dominant wind regimes,
- topographic gradients and slope-driven acceleration effects,
- vegetation continuity and fuel availability,
- and relative dryness differentials between neighboring areas.

This network-based structure allows LynxSense to formalize how localized environmental stress can amplify or transmit risk across space under changing conditions.

#### Inference beyond directly observed locations

Because monitoring infrastructure is concentrated within selected DRCs, large portions of the territory remain only partially instrumented. Spatial inference models are therefore used to estimate risk conditions in areas that are not directly observed.

Rather than producing deterministic fire trajectories, these models infer **relative risk gradients**, **plausible propagation corridors**, and **structurally critical zones** within the landscape. The objective is not to predict exact fire behavior, but to provide a coherent and interpretable representation of how risk may evolve spatially under prevailing environmental conditions.

#### Landscape-scale risk representation

By integrating localized observations within DRCs and spatial inference across the network, LynxSense produces a **landscape-scale representation of wildfire risk**. This representation captures both local intensity and systemic exposure arising from spatial connectivity.

Such a representation supports strategic prioritization by highlighting areas where risk is increasing, zones that may act as conduits for rapid propagation, and regions whose monitoring or protection has disproportionate importance within the overall system.

### 4. End-to-end methodological flow: from data acquisition to dynamic risk mapping

This section provides a transversal overview of the LynxSense methodology, illustrating how the different components interact along the full information chain—from initial data collection to the production of dynamic risk maps and alert signals.

#### From environmental data acquisition to structural vulnerability assessment

At the methodological level, LynxSense relies on a **progressive data enrichment strategy**.  
The framework begins with exogenous, institutionally available datasets and gradually transitions toward localized, high-resolution monitoring.

The initial phase exclusively mobilizes **pre-deployment data**, including:

- topography and land-cover maps,
- historical fire records,
- long-term climatic and meteorological patterns,
- satellite-derived vegetation and hydric stress indicators,
- and expert knowledge from local stakeholders.

These sources are combined to characterize the territory as a heterogeneous spatial domain, where each location is associated with a vector of environmental features describing vegetation, topography, hydrology, climate exposure, anthropogenic pressure, and historical fire memory.

This information is synthesized into a **structural vulnerability representation**, designed to reflect long-term susceptibility to ignition and propagation, independently of short-term weather fluctuations.

#### Structural vulnerability mapping and hotspot preselection

The structural vulnerability representation serves as the analytical foundation of the framework.  
It does not describe operational risk, but identifies zones that are **structurally predisposed** to ignition or rapid fire spread due to persistent environmental and anthropogenic conditions.

From this representation, a subset of **high-vulnerability hotspots** is extracted using threshold-based or quantile-based selection methods. These hotspots form the candidate pool from which Dynamic Risk Clusters are defined.

This step ensures that monitoring resources are allocated to zones where the **expected informational gain** is highest.

#### Transition from structural analysis to dynamic monitoring

The selection of Dynamic Risk Clusters marks a **methodological change of regime**.

Before DRC selection, the framework operates in a static, long-term analytical mode, relying on historical and structural data. After selection, LynxSense enters a dynamic monitoring regime, in which localized environmental states are continuously observed and updated.

Dynamic Risk Clusters therefore act as **anchors between long-term vulnerability assessment and real-time risk monitoring**, bridging the gap between large-scale environmental knowledge and fine-scale ground reality.

#### From DRC instrumentation to dynamic risk estimation

Once selected, DRCs are instrumented with localized monitoring devices, including environmental IoT sensors and, where relevant, autonomous drone-based observation systems.

These devices provide high-frequency measurements of microclimatic conditions, vegetation stress, and fuel dryness. Their outputs are continuously ingested into the analytical pipeline, where data streams are synchronized, validated, and fused.

At this stage, processed observations feed the spatio-temporal analytical engine responsible for estimating the **current state of wildfire risk** at the cluster level. This engine integrates temporal dynamics, spatial interactions between neighboring clusters, and propagation pathways driven by wind, topography, and fuel continuity.

Rather than producing deterministic forecasts, the system infers **relative risk intensities and gradients**, reflecting the likelihood of ignition and short-term propagation under prevailing conditions.

#### Construction of the dynamic risk map

Outputs from the spatio-temporal inference engine are aggregated to produce a **Dynamic Risk Map**, representing wildfire risk as a continuously updated surface over the monitored territory.

This map combines:

- localized risk estimates within Dynamic Risk Clusters,
- inferred risk levels in surrounding, non-instrumented areas,
- and network effects arising from inter-cluster spatial interactions.

Methodologically, the Dynamic Risk Map constitutes the **operational synthesis** of the LynxSense framework, translating complex environmental dynamics into an interpretable spatial representation.

#### Risk indicators and alert thresholds

At each update cycle, LynxSense computes a set of **risk indicators** derived from the Dynamic Risk Map. These indicators are designed to be spatially comparable, temporally consistent, and interpretable by non-technical stakeholders.

They capture both local risk intensity and systemic exposure arising from spatial concentration and connectivity.

To support operational monitoring, the framework defines **risk thresholds** corresponding to different alert levels. When thresholds are exceeded, the system generates localized alerts indicating areas requiring increased attention.

These alerts do not trigger automated interventions. They function as **decision-support signals**, enabling authorities to prioritize surveillance, preparedness measures, or preventive actions according to their operational judgment.

### 5. Methodological synthesis, decision support, and evaluability

In summary, the LynxSense methodological framework combines **targeted environmental sampling**, **continuous multi-source data integration**, and **spatial inference** to structure wildfire risk information across time and space.

Dynamic Risk Clusters provide the structural foundation of the system by concentrating monitoring efforts on zones with the highest informational value. The analytical pipeline transforms heterogeneous environmental observations into coherent, continuously updated risk signals. Propagation and spatial inference models extend these signals beyond directly observed locations, producing a landscape-scale understanding of wildfire dynamics.

Together, these components enable LynxSense to generate **Dynamic Risk Maps**, associated risk indicators, and alert levels that synthesize complex environmental processes into interpretable outputs. These outputs do not constitute operational decisions. Instead, they modify the **information environment** in which public authorities operate, reducing uncertainty and improving situational awareness.

This strict separation between information production and decision-making is a deliberate methodological choice. It ensures institutional compatibility, preserves accountability, and allows LynxSense to integrate seamlessly within existing national and European governance frameworks.

Importantly, the design of the framework prioritizes **interpretability, traceability, and evaluability** over opaque optimization. Each stage of the methodological pipeline produces observable intermediate outputs—coverage, latency, risk indicators, and alerts—that can be documented, audited, and analyzed ex post.

As such, LynxSense provides a clear and measurable interface for subsequent evaluation. The information produced by the framework can be directly linked to observed decision-making behavior, enabling econometric analyses aimed at assessing whether improved risk awareness leads to more timely, better-targeted, and more proportionate public actions under conditions of uncertainty and constrained resources.

While the detailed technical implementation is presented in the Technical Core (Annex), the present section establishes the **conceptual and methodological architecture** of the LynxSense framework. It provides the foundation required to assess its feasibility, relevance, and potential contribution to more effective and anticipatory wildfire risk governance.

The econometric evaluation remains agnostic regarding the internal technical architecture of LynxSense, and focuses exclusively on the information effectively made available to decision-makers.

# V. Econometric Evaluation Framework


The LynxSense framework is conceived as a **public decision-support system**, aimed at improving wildfire risk governance by strengthening the **informational environment** in which public authorities operate. The system does not seek to act directly on the physical environment, nor to prevent wildfire occurrence mechanically, but to provide decision-makers with a **Dynamic Risk Map**, accompanied by operational metadata describing the **coverage**, **latency**, and overall quality of the information delivered.

In a context characterized by high environmental uncertainty and binding budgetary and operational constraints, the performance of public action depends less on the quantity of decisions taken than on their **alignment with the level of risk effectively observed**. From an empirical perspective, this implies that the relevant object of evaluation is not the impact of LynxSense on wildfire occurrence—an outcome that is both indirect and difficult to identify—but rather whether the information provided by the system is **effectively integrated into the public decision-making process**.

The econometric evaluation therefore focuses on assessing whether, conditional on a given level of environmental risk, improvements in the informational context delivered by LynxSense lead public authorities to take **more proportionate, more reactive, and better targeted decisions**. In other words, the analysis seeks to determine whether LynxSense improves **decision quality under uncertainty**, rather than increasing decision intensity per se.

The central causal question guiding the econometric analysis is the following:

*To what extent does the use of the Dynamic Risk Map produced by the LynxSense framework improve the alignment of public decisions with the observed level of wildfire risk, by enhancing the sensitivity of public authorities to risk signals under conditions of uncertainty and limited resources?*

Equivalently, the analysis asks whether the **informational shock** generated by LynxSense—through improvements in information coverage and latency—modifies the public decision function by increasing the responsiveness of authorities to environmental risk signals, for a given level of underlying risk.

LynxSense is thus interpreted as an **exogenous informational shock** that affects how decisions are made, without directly affecting the physical environment. The expected effect is not a mechanical increase in public action, but a **systematic change in the relationship between observed risk and decisions taken**.

From an empirical standpoint, an improvement in the decision-making process should manifest itself through :

- a stronger response when risk levels are high,
- a limitation of costly decisions when risk levels are low,
- and an overall improvement in the proportionality of public action.

Econometrically, this translates into testing whether the **slope of the decision–risk relationship** becomes steeper as the informational environment improves.

### 1) Data structure and territorial risk signal 

The econometric analysis relies on a **panel dataset** structured at the level of decision-making territory $j$ over time $t$.

Two main data sources are mobilized :

- operational data and metadata generated by the LynxSense system,
- publicly available data on administrative decisions related to wildfire prevention and preparedness.

#### Territorial Risk Signal from the Dynamic Risk Map

The LynxSense Dynamic Risk Map associates to each spatial cell  $\Omega_i$ $\in \Omega$  a continuous measure of ignition and propagation risk :

$$R(\Omega_i,t) \in [0,1]$$

Public decisions, however, are taken at the level of administrative territories, indexed by $j$, each covering a set of spatial cells. Let :

$$\mathcal{I}(j) = \{ \ i \ | \ \Omega_i \subset j \ \}$$

denote the set of cells belonging to territory $j$.

To link the risk signal to the level at which decisions are made, a **territorially aggregated risk measure** is defined as :

$$Risk_{jt} = \mathcal{A}(\{R(\Omega_i,t) : i \in \mathcal{I}(j) \})$$

where $\mathcal{A}(*)$ is a pre-specified aggregation operator (e.g. maximum risk, high quantile).

The variable $Risk_{jt}$ ​ represents the **effective risk signal perceived by the decision-maker**, and constitutes the core explanatory variable capturing the environmental constraint faced by public authorities.

### 2) Treatment Definition: Information Quality

LynxSense is modeled as a technology that improves the **quality of the informational context** available to public authorities. Accordingly, the econometric treatment corresponds to an exogenous variation in information quality at the territory–time level.

**Information Quality Synthetic Index (IQSI)**

The treatment is defined as a **continuous measure** of information quality, captured through an **Information Quality Synthetic Index (IQSI)**, bounded between 0 and 1.

For each territory $j$ and period $t$, the IQSI measures the effective quality of the risk signal made available to the decision-maker, based on operational metadata generated by the LynxSense platform.

The index relies on two non-redundant and directly observable dimensions :

- $C_{j,t}$ (**effective spatial coverage**): the share of territory $j$ for which a valid risk value $R(\Omega_i,t)$ is available. This component captures the degree of **spatial completeness** of the information transmitted to the decision-maker.
- $L_{j,t}$ (**information timeliness – latency**): the average latency of risk signal dissemination, defined as the time elapsed between data acquisition by the LynxSense system and the effective availability of the information to the decision-maker through the Dynamic Risk Map.

In order to preserve a **monotonically increasing interpretation** of the index, a timeliness measure is defined as:

$$T_{j,t} = 1 - L_{j,t}^{normalized}$$
with $w_C + w_T = 1$.

The weights $(w_C, w_T)$ are fixed ex ante in the analysis to reflect the operational trade-off between spatial completeness and signal timeliness.

As a baseline specification, balanced weights $(0.5, 0.5)$ are adopted, reflecting a neutral weighting scheme.

The relevance of these weights can be discussed and is addressed through **robustness checks**, aimed at assessing the stability of the econometric results under alternative weighting schemes.

Robustness is tested by re-estimating the model using alternative weight configurations favoring timeliness $(0.4, 0.6)$ or spatial coverage $(0.6, 0.4)$, as well as under extreme scenarios prioritizing immediate crisis response or long-term territorial prevention.

A high value of $IQSI_{j,t}$ corresponds to a **high-quality informational environment**, in which the decision-maker benefits from :

- a **spatially complete risk signal**, covering a large share of the decision-maker’s intervention territory, thereby limiting informational blind spots and strengthening the coherence between available operational capacities and perceived risk;

- a **temporally relevant risk signal**, disseminated with low latency, such that the time gap between data acquisition by the system and access to interpretable information by the decision-maker is minimized.

Within this framework, the effective frequency of risk signal updates is not treated as an autonomous dimension, but rather as a **direct consequence of low latency** in the information production and dissemination process.

### 3) Decision-making outcomes  

The objective is to analyze how improvements in information quality affect the decision-making behavior of public authorities, in particular by influencing their **responsiveness** and **resource allocation**, which constitute the main channels through which better information may enhance the effectiveness of public action.

**Decision responsiveness**

The first outcome variable measures the **responsiveness of public decision-makers** to a given risk signal.

For each territory $j$ and period $t$, we define the response delay (in hours or days):

$$Delay_{j,t}$$

This variable corresponds to the time elapsed between the effective availability of a relevant risk signal $Risk_{j,t}$ through the Dynamic Risk Map and the implementation of a first observable public action related to prevention or preparedness.

This delay provides a direct measure of the ability of public authorities to rapidly translate available information into operational decisions. A decrease in $Delay_{j,t}$ therefore reflects an improvement in decision responsiveness.

When a continuous measure of the delay is not available, an alternative binary variable can be used, indicating whether an action is undertaken within a given time window (for instance on the same day or within 24 hours following the observation of the risk signal).

**Resource allocation**

The second outcome variable aims to capture the **intensity of operational effort** mobilized by public authorities in response to the risk signal.

We define the variable:

$$Effort_{j,t}$$

which measures, for each territory and period, the level of resources engaged for prevention or preparedness purposes. This variable can be proxied by observable operational indicators, such as:

- the number or duration of surveillance patrols;
- the number of reconnaissance or aerial monitoring missions;
- the volume of preventive actions triggered;

or any equivalent measure reflecting the deployment of public resources.

This variable allows us to assess not only whether authorities act more intensively, but, more importantly, whether they **adjust the intensity of their action to the observed level of risk**, conditional on the quality of the information available.

In this framework, improvements in information quality provided by LynxSense are not expected to mechanically increase public action, but rather to **improve its targeting and timeliness**. Higher-quality information should translate into faster decisions when risk is high, and into a more proportionate mobilization of resources in response to variations in territorial risk.


### 4) Econometric model and identification strategy  

The objective of the econometric model is to identify to what extent improvements in information quality provided by LynxSense, measured by $IQSI_{j,t}$, modify the way public authorities translate a risk signal $Risk_{j,t}$ into an operational decision.

The goal is therefore not to estimate an average “level effect” of information on public action, but a **conditional effect**: improved information is expected to strengthen the alignment of decisions with the observed level of risk.

For each territory $j$ and period $t$, we estimate a fixed-effects panel model of the following form :

$$Outcome_{j,t} = \alpha + \beta_1 Risk_{j,t} + \beta_2(Risk_{j,t}\times IQSI_{j,t} ) + \beta_3IQSI_{j,t} + \mu_j + \sigma_t + \epsilon_{j,t}$$

where:

- $Outcome_{j,t}$ alternatively denotes decision responsiveness $Delay_{j,t}$ or operational effort intensity $Effort_{j,t}$;
- $Risk_{j,t}$ is the aggregated territorial risk signal derived from the Dynamic Risk Map;
- $IQSI_{j,t}$ measures the quality of the information signal made available to the decision-maker (spatial coverage and timeliness);
- $\mu_j$ captures **territorial fixed effects**, controlling for unobserved and time-invariant characteristics specific to each territory (local organization, topography, structural vulnerability, etc.);
- $\delta_t$ denotes **time fixed effects**, controlling for common shocks and seasonality (high-risk periods, general conditions, regulatory changes, etc.);
- $\epsilon_{j,t}$ is the error term.

The coefficient $\beta_2$ is the **central parameter** of the analysis. It measures the extent to which information quality increases the **sensitivity of public decisions to the observed level of risk**. Formally, the marginal sensitivity of the decision to risk is given by:

$$\frac{\partial Outcome_{j,t}}{\partial Risk_{j,t}} = \beta_1 + \beta_2IQSI_{j,t}$$When $IQSI_{j,t}$ is high, a non-zero value of $\beta_2$ indicates that the decision-maker’s response to risk becomes more pronounced.

- When $Outcome_{j,t} = Delay_{j,t}$, a negative value of $\beta_2$ is expected: for a given level of risk, higher information quality is associated with a **reduction in response delay** as risk increases.

- When $Outcome_{j,t} = Effort_{j,t}$, a positive value of $\beta_2$ is expected: for a given level of risk, higher information quality is associated with a **more intense and better targeted mobilization of resources** as risk increases.

This framework allows LynxSense to be evaluated as an **informational amplifier**: the system does not mechanically increase public action, but improves the ability of public authorities to adjust their decisions to the observed level of risk, which is consistent with a decision-making process under uncertainty and binding resource constraints.


### 5) Assumptions, robustness, and interpretation  


#### 1. Causal identification strategy: a continuous Difference-in-Differences framework

The econometric identification strategy relies on a Difference-in-Differences (DiD) framework adapted to a context in which the treatment is not binary but varies continuously over time and across territories. In the LynxSense framework, information quality does not switch on or off abruptly; instead, it improves progressively and heterogeneously as a result of operational and technical factors affecting spatial coverage and signal latency.

Accordingly, the treatment is modeled as a continuous informational shock, captured by the Information Quality Synthetic Index (IQSI). The DiD logic exploits differences in the evolution of IQSI across territories and over time to construct implicit counterfactuals, allowing for comparisons within the same territory before and after improvements in information quality, while using other territories experiencing different information trajectories as benchmarks.

The originality of the identification strategy lies in the fact that the effect of information quality is not expected to operate in levels, but conditionally on the level of environmental risk. Public authorities are not expected to systematically increase their level of action when information improves; rather, better information should enhance their ability to adjust decisions to the risk effectively observed.

To capture this mechanism, the DiD framework is implemented in a conditional form, through the interaction between the territorial risk signal and information quality. This interaction allows the analysis to identify whether the slope of the decision–risk relationship changes as the informational environment improves. In this sense, the econometric strategy does not test whether LynxSense increases public action on average, but whether it strengthens the responsiveness of decisions to risk.

Within this framework, identification relies on comparisons both over time and across territories. For a given territory, changes in decision behavior observed after an improvement in information quality are compared to decision patterns observed before such improvements. At the same time, territories experiencing different trajectories of IQSI over the same period provide implicit counterfactuals.

Territorial fixed effects ensure that each territory is effectively compared to itself over time, controlling for all time-invariant institutional, geographic, and organizational characteristics. Time fixed effects absorb common shocks and seasonal dynamics affecting all territories simultaneously. Together, these features allow the DiD framework to isolate the effect of changes in the informational environment from confounding structural differences or aggregate trends.

#### 2. Identification assumptions

The causal interpretation of the estimated effects relies on a set of explicit and realistic assumptions, consistent with the institutional and operational context of the LynxSense framework.

First, conditional on territorial and time fixed effects, variations in information quality (IQSI) are assumed to be exogenous to short-term public decision-making behavior. This assumption is plausible insofar as IQSI is primarily driven by technical and operational constraints—such as sensor availability, data transmission conditions, and system performance—rather than by discretionary choices made by local authorities.

Second, the identification strategy relies on a conditional parallel trends assumption. In the absence of improvements in information quality, the relationship between observed wildfire risk and public decision-making would have evolved similarly over time within a given territory. Given the progressive, non-targeted, and technically driven nature of changes in IQSI, this assumption is consistent with the institutional setting under consideration.

Third, the territorial risk signal is assumed to be exogenous to the decision-making process. Risk measures are constructed from environmental, meteorological, and spatial data that are independent of contemporaneous public actions, ensuring that variations in observed risk are not mechanically driven by the decisions they are meant to explain.

#### 3. Robustness analysis

To assess the robustness of the econometric results, several complementary checks are implemented to ensure that the estimated effects are not driven by arbitrary modeling choices or specific data constructions.

First, the model is re-estimated under alternative weighting schemes for the Information Quality Synthetic Index (IQSI), varying the relative importance assigned to spatial coverage and information timeliness. This allows us to verify that the results are not sensitive to a particular ex ante weighting choice.

Second, alternative definitions of the territorial risk signal are considered. The aggregation operator used to construct the territorial risk measure from the Dynamic Risk Map is varied (e.g. maximum risk versus high quantiles), in order to verify that the estimated effects are not driven by a specific representation of the risk signal perceived by decision-makers.

Third, when data availability permits, placebo tests and pre-trend analyses are conducted. These tests aim to verify that changes in decision outcomes do not systematically precede improvements in information quality, thereby supporting the validity of the conditional parallel trends assumption underlying the DiD framework.

#### 4. Interpretation and scope of the results

Within this econometric framework, LynxSense is interpreted as an **informational amplifier** embedded in the public decision-making process. A statistically significant interaction between the risk signal and information quality indicates that improvements in the informational environment do not mechanically increase the volume of public action, but instead enhance the **alignment between observed risk levels and the decisions taken by public authorities**.

In practical terms, higher information quality enables public authorities to **react more rapidly when risk levels are high**, while avoiding unnecessary or costly interventions when risk levels are low. This pattern reflects an improvement in the **proportionality and targeting of decisions**, which is central in contexts characterized by binding budgetary, operational, and human resource constraints.

Accordingly, the econometric evaluation does not aim to demonstrate that LynxSense directly reduces wildfire occurrence. Rather, it identifies a **causal behavioral effect** on how public authorities integrate risk information into their decision-making process. This behavioral channel constitutes the primary mechanism through which a decision-support system such as LynxSense can enhance the effectiveness of wildfire risk governance under conditions of uncertainty.

This evaluation framework thus provides a rigorous basis for assessing the decision-support value of LynxSense in operational wildfire risk governance.












# VI. Implementation Strategy, Timeline, and Teams

# VII. Budget

